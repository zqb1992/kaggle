{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root_dir = \"../data\"\n",
    "# 载入数据集\n",
    "train = pd.read_csv('%s/%s' % (root_dir, 'labeledTrainData.tsv'), header=0, delimiter=\"\\t\", quoting=3)\n",
    "test = pd.read_csv('%s/%s' % (root_dir, 'testData.tsv'), header=0, delimiter=\"\\t\", quoting=3)\n",
    "test[\"id\"] = test[\"id\"].apply(lambda x: eval(x))\n",
    "print(train.shape)\n",
    "print(train.columns.values)\n",
    "print(train.head(3))\n",
    "print(test.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 去除评论中的HTML标签\n",
    "print('\\n处理前: \\n', train['review'][0])\n",
    "\n",
    "example1 = BeautifulSoup(train['review'][0], \"html.parser\")\n",
    "\n",
    "import re\n",
    "# Use regular expressions to do a find-and-replace\n",
    "letters_only = re.sub('[^a-zA-Z]',  # 搜寻的pattern\n",
    "                      ' ',           # 用来替代的pattern(空格)\n",
    "                      example1.get_text())  # 待搜索的text \n",
    "\n",
    "print(letters_only)\n",
    "lower_case = letters_only.lower()  # Convert to lower case\n",
    "words = lower_case.split()  # Split into word\n",
    "\n",
    "print('\\n处理后: \\n', words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def review_to_wordlist(review):\n",
    "    '''\n",
    "    把IMDB的评论转成词序列\n",
    "    参考：http://blog.csdn.net/longxinchen_ml/article/details/50629613\n",
    "    '''\n",
    "    # 去掉HTML标签，拿到内容\n",
    "    review_text = BeautifulSoup(review, \"html.parser\").get_text()\n",
    "    # 用正则表达式取出符合规范的部分\n",
    "    review_text = re.sub(\"[^a-zA-Z]\", \" \", review_text)\n",
    "    # 小写化所有的词，并转成词list\n",
    "    words = review_text.lower().split()\n",
    "    # 返回words\n",
    "    return words\n",
    "\n",
    "\n",
    "# 预处理数据\n",
    "label = train['sentiment']\n",
    "train_data = []\n",
    "for i in range(len(train['review'])):\n",
    "    train_data.append(' '.join(review_to_wordlist(train['review'][i])))\n",
    "test_data = []\n",
    "for i in range(len(test['review'])):\n",
    "    test_data.append(' '.join(review_to_wordlist(test['review'][i])))\n",
    "\n",
    "# 预览数据\n",
    "print(train_data[0], '\\n')\n",
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer as TFIDF\n",
    "# 参考：http://blog.csdn.net/longxinchen_ml/article/details/50629613\n",
    "\n",
    "\"\"\"\n",
    "min_df: 最小支持度为2（词汇出现的最小次数）\n",
    "max_features: 默认为None，可设为int，对所有关键词的term frequency进行降序排序，只取前max_features个作为关键词集\n",
    "strip_accents: 将使用ascii或unicode编码在预处理步骤去除raw document中的重音符号\n",
    "analyzer: 设置返回类型\n",
    "token_pattern: 表示token的正则表达式，需要设置analyzer == 'word'，默认的正则表达式选择2个及以上的字母或数字作为token，标点符号默认当作token分隔符，而不会被当作token\n",
    "ngram_range: 词组切分的长度范围\n",
    "use_idf: 启用逆文档频率重新加权\n",
    "use_idf：默认为True，权值是tf*idf，如果设为False，将不使用idf，就是只使用tf，相当于CountVectorizer了。\n",
    "smooth_idf: idf平滑参数，默认为True，idf=ln((文档总数+1)/(包含该词的文档数+1))+1，如果设为False，idf=ln(文档总数/包含该词的文档数)+1\n",
    "sublinear_tf: 默认为False，如果设为True，则替换tf为1 + log(tf)\n",
    "stop_words: 设置停用词，设为english将使用内置的英语停用词，设为一个list可自定义停用词，设为None不使用停用词，设为None且max_df∈[0.7, 1.0)将自动根据当前的语料库建立停用词表\n",
    "\"\"\"\n",
    "tfidf = TFIDF(min_df=2,\n",
    "           max_features=None,\n",
    "           strip_accents='unicode',\n",
    "           analyzer='word',\n",
    "           token_pattern=r'\\w{1,}',\n",
    "           ngram_range=(1, 3),  # 二元文法模型\n",
    "           use_idf=1,\n",
    "           smooth_idf=1,\n",
    "           sublinear_tf=1,\n",
    "           stop_words = 'english') # 去掉英文停用词\n",
    "\n",
    "# 合并训练和测试集以便进行TFIDF向量化操作\n",
    "data_all = train_data + test_data\n",
    "len_train = len(train_data)\n",
    "\n",
    "tfidf.fit(data_all)\n",
    "data_all = tfidf.transform(data_all)\n",
    "# 恢复成训练集和测试集部分\n",
    "train_x = data_all[:len_train]\n",
    "test_x = data_all[len_train:]\n",
    "print('TF-IDF处理结束.')\n",
    "\n",
    "print(\"train: \\n\", np.shape(train_x[0]))\n",
    "print(\"test: \\n\", np.shape(test_x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 朴素贝叶斯训练\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB as MNB\n",
    "\n",
    "model_NB = MNB() # (alpha=1.0, class_prior=None, fit_prior=True)\n",
    "# 为了在预测的时候使用\n",
    "model_NB.fit(train_x, label)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "print(\"多项式贝叶斯分类器10折交叉验证得分:  \\n\", cross_val_score(model_NB, train_x, label, cv=10, scoring='roc_auc'))\n",
    "print(\"\\n多项式贝叶斯分类器10折交叉验证得分: \", np.mean(cross_val_score(model_NB, train_x, label, cv=10, scoring='roc_auc')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_predicted = np.array(model_NB.predict(test_x))\n",
    "print('保存结果...')\n",
    "\n",
    "submission_df = pd.DataFrame(data ={'id': test['id'], 'sentiment': test_predicted})\n",
    "print(submission_df.head(10))\n",
    "submission_df.to_csv('../out/submission_br.csv',columns = ['id','sentiment'], index = False)\n",
    "\n",
    "# nb_output = pd.DataFrame(data=test_predicted, columns=['sentiment'])\n",
    "# nb_output['id'] = test['id']\n",
    "# nb_output = nb_output[['id', 'sentiment']]\n",
    "# nb_output.to_csv('nb_output.csv', index=False)\n",
    "print('结束.')\n",
    "\n",
    "'''\n",
    "1.提交最终的结果到kaggle，AUC为：0.85728，排名300左右，50%的水平\n",
    "2. ngram_range = 3, 三元文法，AUC为0.85924\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 设定grid search的参数\n",
    "grid_values = {'C': [1, 15, 30, 50]}  \n",
    "# grid_values = {'C': [30]}\n",
    "# 设定打分为roc_auc\n",
    "\"\"\"\n",
    "penalty: l1 or l2, 用于指定惩罚中使用的标准。\n",
    "\"\"\"\n",
    "model_LR = GridSearchCV(LR(penalty='l2', dual=True, random_state=0), grid_values, scoring='roc_auc', cv=20)\n",
    "model_LR.fit(train_x, label)\n",
    "# 20折交叉验证\n",
    "# GridSearchCV(cv=20, \n",
    "#         estimator=LR(C=1.0, \n",
    "#             class_weight=None, \n",
    "#             dual=True, \n",
    "#             fit_intercept=True, \n",
    "#             intercept_scaling=1, \n",
    "#             penalty='l2', \n",
    "#             random_state=0, \n",
    "#             tol=0.0001),\n",
    "#         fit_params={}, \n",
    "#         iid=True,\n",
    "#         n_jobs=1,\n",
    "#         param_grid={'C': [30]}, \n",
    "#         pre_dispatch='2*n_jobs',\n",
    "#         refit=True,\n",
    "#         scoring='roc_auc', \n",
    "#         verbose=0)\n",
    "\n",
    "# 输出结果\n",
    "# print(model_LR.grid_scores_, '\\n', model_LR.best_params_, model_LR.best_params_)\n",
    "print(model_LR.cv_results_, '\\n', model_LR.best_params_, model_LR.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_LR = LR(penalty='l2', dual=True, random_state=0)\n",
    "model_LR.fit(train_x, label)\n",
    "\n",
    "test_predicted = np.array(model_LR.predict(test_x))\n",
    "print('保存结果...')\n",
    "\n",
    "test[\"sentiment\"] = test_predicted\n",
    "test = test[['id','sentiment']]\n",
    "test.to_csv('../out/submission_lr.csv',index=False)\n",
    "\n",
    "\n",
    "'''\n",
    "1. 提交最终的结果到kaggle，AUC为：0.88956，排名260左右，比之前贝叶斯模型有所提高\n",
    "2. 三元文法，AUC为0.89076\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
