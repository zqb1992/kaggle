{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参考地址\n",
    "[Kaggle竞赛-房价预测（House Prices）小结](https://zhuanlan.zhihu.com/p/39429689)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#导入相关依赖库\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import norm\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#机器学习裤\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#读入训练数据，观察OverallQual、GrLivArea、YearBuilt、TotalBsmtSF四项数据对销售价格的影响\n",
    "train_data=pd.read_csv('../data/train.csv')\n",
    "figure=plt.figure()\n",
    "sns.pairplot(x_vars=['OverallQual','GrLivArea','YearBuilt','TotalBsmtSF'],y_vars=['SalePrice'],data=train_data,dropna=True) #绘制多变量图\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#将离群点清除\n",
    "train_data.drop(train_data[(train_data['OverallQual']<5) & (train_data['SalePrice']>200000)].index,inplace=True)\n",
    "train_data.drop(train_data[(train_data['GrLivArea']>4000) & (train_data['SalePrice']<200000)].index,inplace=True)\n",
    "train_data.drop(train_data[(train_data['YearBuilt']<1900) & (train_data['SalePrice']>400000)].index,inplace=True)\n",
    "train_data.drop(train_data[(train_data['TotalBsmtSF']>6000) & (train_data['SalePrice']<200000)].index,inplace=True)\n",
    "train_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#读入测试集数据，并与训练集合并在一起，一起进行数据清洗和特征工程\n",
    "test_data=pd.read_csv('../data/test.csv')\n",
    "my_data=pd.concat([train_data,test_data],axis=0)\n",
    "my_data.reset_index(drop=True, inplace=True)\n",
    "train_index=train_data.index\n",
    "test_index=list(set(my_data.index).difference(set(train_data.index)))\n",
    "# Some of the non-numeric predictors are stored as numbers; we convert them into strings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#查看缺失值\n",
    "all_data=pd.concat([train_data,test_data])\n",
    "count=all_data.isnull().sum().sort_values(ascending=False)\n",
    "ratio=count/len(all_data)\n",
    "nulldata=pd.concat([count,ratio],axis=1,keys=['count','ratio'])\n",
    "print(nulldata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#观察变量之间的相关性\n",
    "corrmat = train_data.corr()\n",
    "plt.subplots(figsize=(20,12))\n",
    "sns.heatmap(corrmat, vmax=0.9, square=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 寻找K个最相关的特征信息\n",
    "k = 10 # number of variables for heatmap\n",
    "#print(train_corr.nlargest(k, 'SalePrice')['SalePrice'])\n",
    "cols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index #nlargest查看最大的元素\n",
    "#print(cols.values)\n",
    "cm = np.corrcoef(train_data[cols].values.T)\n",
    "sns.set(font_scale=1.5)\n",
    "hm = plt.subplots(figsize=(20, 12))#调整画布大小\n",
    "hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#填充缺失值,mode函数求的是众数\n",
    "def fill_missings(res):\n",
    "\n",
    "    res['Alley'] = res['Alley'].fillna('missing')\n",
    "    res['PoolQC'] = res['PoolQC'].fillna(res['PoolQC'].mode()[0])\n",
    "    res['MasVnrType'] = res['MasVnrType'].fillna('None')\n",
    "    res['BsmtQual'] = res['BsmtQual'].fillna(res['BsmtQual'].mode()[0])\n",
    "    res['BsmtCond'] = res['BsmtCond'].fillna(res['BsmtCond'].mode()[0])\n",
    "    res['FireplaceQu'] = res['FireplaceQu'].fillna(res['FireplaceQu'].mode()[0])\n",
    "    res['GarageType'] = res['GarageType'].fillna('missing')\n",
    "    res['GarageFinish'] = res['GarageFinish'].fillna(res['GarageFinish'].mode()[0])\n",
    "    res['GarageQual'] = res['GarageQual'].fillna(res['GarageQual'].mode()[0])\n",
    "    res['GarageCond'] = res['GarageCond'].fillna('missing')\n",
    "    res['Fence'] = res['Fence'].fillna('missing')\n",
    "    res['Street'] = res['Street'].fillna('missing')\n",
    "    res['LotShape'] = res['LotShape'].fillna('missing')\n",
    "    res['LandContour'] = res['LandContour'].fillna('missing')\n",
    "    res['BsmtExposure'] = res['BsmtExposure'].fillna(res['BsmtExposure'].mode()[0])\n",
    "    res['BsmtFinType1'] = res['BsmtFinType1'].fillna('missing')\n",
    "    res['BsmtFinType2'] = res['BsmtFinType2'].fillna('missing')\n",
    "    res['CentralAir'] = res['CentralAir'].fillna('missing')\n",
    "    res['Electrical'] = res['Electrical'].fillna(res['Electrical'].mode()[0])\n",
    "    res['MiscFeature'] = res['MiscFeature'].fillna('missing')\n",
    "    res['MSZoning'] = res['MSZoning'].fillna(res['MSZoning'].mode()[0])    \n",
    "    res['Utilities'] = res['Utilities'].fillna('missing')\n",
    "    res['Exterior1st'] = res['Exterior1st'].fillna(res['Exterior1st'].mode()[0])\n",
    "    res['Exterior2nd'] = res['Exterior2nd'].fillna(res['Exterior2nd'].mode()[0])    \n",
    "    res['KitchenQual'] = res['KitchenQual'].fillna(res['KitchenQual'].mode()[0])\n",
    "    res[\"Functional\"] = res[\"Functional\"].fillna(\"Typ\")\n",
    "    res['SaleType'] = res['SaleType'].fillna(res['SaleType'].mode()[0])\n",
    "    # res['SaleCondition'] = res['SaleCondition'].fillna('missing')\n",
    "    #数值型变量的空值先用0值替换\n",
    "    flist = ['LotFrontage','LotArea','MasVnrArea','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF',\n",
    "                     'TotalBsmtSF','1stFlrSF','2ndFlrSF','LowQualFinSF','GrLivArea',\n",
    "                     'BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr','KitchenAbvGr',\n",
    "                     'TotRmsAbvGrd','Fireplaces','GarageCars','GarageArea','WoodDeckSF','OpenPorchSF',\n",
    "                     'EnclosedPorch','3SsnPorch','ScreenPorch','PoolArea','MiscVal','GarageYrBlt']\n",
    "    for fl in flist:\n",
    "        res[fl] = res[fl].fillna(0)\n",
    "    #0值替换   \n",
    "    res['TotalBsmtSF'] = res['TotalBsmtSF'].apply(lambda x: np.exp(6) if x <= 0.0 else x)\n",
    "    res['2ndFlrSF'] = res['2ndFlrSF'].apply(lambda x: np.exp(6.5) if x <= 0.0 else x)\n",
    "    res['GarageArea'] = res['GarageArea'].apply(lambda x: np.exp(6) if x <= 0.0 else x)\n",
    "    res['GarageCars'] = res['GarageCars'].apply(lambda x: 0 if x <= 0.0 else x)\n",
    "    res['LotFrontage'] = res['LotFrontage'].apply(lambda x: np.exp(4.2) if x <= 0.0 else x)\n",
    "    res['MasVnrArea'] = res['MasVnrArea'].apply(lambda x: np.exp(4) if x <= 0.0 else x)\n",
    "    res['BsmtFinSF1'] = res['BsmtFinSF1'].apply(lambda x: np.exp(6.5) if x <= 0.0 else x)    \n",
    "    return res\n",
    "mydata=fill_missings(my_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#检查是否还有缺失值\n",
    "count=mydata.isnull().sum().sort_values(ascending=False)\n",
    "ratio=count/len(mydata)\n",
    "nulldata=pd.concat([count,ratio],axis=1,keys=['count','ratio'])\n",
    "print(nulldata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#数据类型转换\n",
    "mydata['MSSubClass'] = mydata['MSSubClass'].apply(str)\n",
    "mydata['YrSold'] = mydata['YrSold'].astype(str)\n",
    "mydata['MoSold'] = mydata['MoSold'].astype(str)\n",
    "all_data['OverallCond'] = all_data['OverallCond'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#顺序特征编码\n",
    "mydata['TotalSF'] = mydata['TotalBsmtSF'] + mydata['1stFlrSF'] + mydata['2ndFlrSF']\n",
    "def QualToInt(x):\n",
    "    if(x=='Ex'):\n",
    "        r = 0\n",
    "    elif(x=='Gd'):\n",
    "        r = 1\n",
    "    elif(x=='TA'):\n",
    "        r = 2\n",
    "    elif(x=='Fa'):\n",
    "        r = 3\n",
    "    elif(x=='missing'):\n",
    "        r = 4\n",
    "    else:\n",
    "        r = 5\n",
    "    return r\n",
    "mydata['ExterQual'] = mydata['ExterQual'].apply(QualToInt)\n",
    "mydata['ExterCond'] = mydata['ExterCond'].apply(QualToInt)\n",
    "mydata['KitchenQual'] = mydata['KitchenQual'].apply(QualToInt)\n",
    "mydata['HeatingQC'] = mydata['HeatingQC'].apply(QualToInt)\n",
    "mydata['BsmtQual'] = mydata['BsmtQual'].apply(QualToInt)\n",
    "mydata['BsmtCond'] = mydata['BsmtCond'].apply(QualToInt)\n",
    "mydata['FireplaceQu'] = mydata['FireplaceQu'].apply(QualToInt)\n",
    "mydata['GarageQual'] = mydata['GarageQual'].apply(QualToInt)\n",
    "mydata['PoolQC'] = mydata['PoolQC'].apply(QualToInt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#组合特征，添加新的特征\n",
    "#将totalBsmtSF/1stFlrSF/2ndFlrSF变量组合新的特征\n",
    "mydata['TotalSF'] = mydata['TotalBsmtSF'] + mydata['1stFlrSF'] + mydata['2ndFlrSF']\n",
    "\n",
    "#房屋是否有别的区域空间\n",
    "mydata['HasWoodDeck'] = (mydata['WoodDeckSF'] == 0) * 1\n",
    "mydata['HasOpenPorch'] = (mydata['OpenPorchSF'] == 0) * 1\n",
    "mydata['HasEnclosedPorch'] = (mydata['EnclosedPorch'] == 0) * 1\n",
    "mydata['Has3SsnPorch'] = (mydata['3SsnPorch'] == 0) * 1\n",
    "mydata['HasScreenPorch'] = (mydata['ScreenPorch'] == 0) * 1\n",
    "\n",
    "#房屋买卖间隔时间\n",
    "mydata['YearsSinceRemodel'] = mydata['YrSold'].astype(int) - mydata['YearRemodAdd'].astype(int)\n",
    "\n",
    "#房屋整体质量\n",
    "mydata['Total_Home_Quality'] = mydata['OverallQual'] + mydata['OverallCond']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#数据转换\n",
    "quantitative = [f for f in train_data.columns if train_data.dtypes[f] != 'object' and train_data.dtypes[f] != 'str']\n",
    "quantitative.remove('SalePrice')\n",
    "print(quantitative)\n",
    "# f = pd.melt(train_data, value_vars=quantitative)\n",
    "# g = sns.FacetGrid(f, col=\"variable\",  col_wrap=5, sharex=False, sharey=False)\n",
    "# g = g.map(sns.distplot, \"value\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(mydata[quantitative].skew().sort_values(ascending=False))\n",
    "skewed_feats = mydata[quantitative].dropna().skew().sort_values(ascending=False)\n",
    "# mydata['MSSubClass'].astype(float)\n",
    "# skewed_feats = mydata[quantitative].apply(lambda x:skew(x.dropna())).sort_values(ascending=False)\n",
    "skewness = pd.DataFrame({'Skew':skewed_feats})\n",
    "skewness.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "help(skew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def addlogs(res, ls):\n",
    "    m = res.shape[1]\n",
    "    for l in ls:\n",
    "        a=res[l]\n",
    "        res = res.assign(newcol=pd.Series(np.log(1.01+a.astype(float))).values)   \n",
    "        res.columns.values[m] = l + '_log'\n",
    "        m += 1\n",
    "    return res\n",
    "loglist=skewness[abs(skewness)>0.15].index.tolist()\n",
    "mydata = addlogs(mydata, loglist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qualitative = [f for f in train_data.columns if train_data.dtypes[f] == 'object'or train_data.dtypes[f] == 'str']\n",
    "oridnals=['BsmtFinType1','MasVnrType','Foundation','HouseStyle','Functional','BsmtExposure','GarageFinish','PavedDrive','Street',\n",
    "                   'ExterQual', 'PavedDrive','ExterQua','ExterCond','KitchenQual','HeatingQC','BsmtQual','FireplaceQu','GarageQual','PoolQC']\n",
    "qualitative=list(set(qualitative).difference(set(oridnals)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "def getdummies(res, ls):\n",
    "    def encode(encode_df):\n",
    "        encode_df = np.array(encode_df)\n",
    "        enc = OneHotEncoder()\n",
    "        le = LabelEncoder()\n",
    "        le.fit(encode_df)\n",
    "        res1 = le.transform(encode_df).reshape(-1, 1)\n",
    "        enc.fit(res1)\n",
    "        return pd.DataFrame(enc.transform(res1).toarray()), le, enc\n",
    "    decoder = []\n",
    "    outres = pd.DataFrame({'A' : []})\n",
    "\n",
    "    for l in ls:\n",
    "        cat, le, enc = encode(res[l])\n",
    "        cat.columns = [l+str(x) for x in cat.columns]\n",
    "        outres.reset_index(drop=True, inplace=True)\n",
    "        outres = pd.concat([outres, cat], axis = 1)\n",
    "        decoder.append([le,enc])     \n",
    "    return (outres, decoder)\n",
    "catpredlist=qualitative\n",
    "res = getdummies(mydata[catpredlist],catpredlist)\n",
    "df = res[0]\n",
    "decoder = res[1]\n",
    "floatAndordinal=list(set(mydata.columns.values).difference(set(qualitative)))\n",
    "mydata.columns.values\n",
    "print(df.shape)\n",
    "df = pd.concat([df,mydata[floatAndordinal]],axis=1)\n",
    "df.drop(['SalePrice'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=295)\n",
    "df = pd.DataFrame(pca.fit_transform(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train=df.iloc[train_index]\n",
    "df_score=df.iloc[test_index]\n",
    "my_traindata=mydata.iloc[train_index]\n",
    "X=np.array(df_train)\n",
    "X=np.delete(X,0,1)\n",
    "y=np.log(1+np.array(my_traindata['SalePrice']))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Modeling\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import lightgbm as lgb\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import KFold,GridSearchCV\n",
    "nF = 20\n",
    "kf = KFold(n_splits=nF, random_state=241, shuffle=True)\n",
    "\n",
    "test_errors_l2 = []\n",
    "train_errors_l2 = []\n",
    "test_errors_l1 = []\n",
    "train_errors_l1 = []\n",
    "test_errors_GBR = []\n",
    "train_errors_GBR = []\n",
    "test_errors_ENet = []\n",
    "test_errors_LGB = []\n",
    "test_errors_stack = []\n",
    "test_errors_ens = []\n",
    "train_errors_ens = []\n",
    "\n",
    "models = []\n",
    "\n",
    "pred_all = []\n",
    "\n",
    "ifold = 1\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print('fold: ',ifold)\n",
    "    ifold = ifold + 1\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # ridge\n",
    "    l2Regr = Ridge(alpha=9.0, fit_intercept = True)\n",
    "    l2Regr.fit(X_train, y_train)\n",
    "    pred_train_l2 = l2Regr.predict(X_train)\n",
    "    pred_test_l2 = l2Regr.predict(X_test)\n",
    "    \n",
    "    # lasso\n",
    "    l1Regr = make_pipeline(RobustScaler(), Lasso(alpha = 0.0003, random_state=1, max_iter=50000))\n",
    "    l1Regr.fit(X_train, y_train)\n",
    "    pred_train_l1 = l1Regr.predict(X_train)\n",
    "    pred_test_l1 = l1Regr.predict(X_test)\n",
    "    \n",
    "    # GBR      \n",
    "    myGBR = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.02,\n",
    "                                      max_depth=4, max_features='sqrt',\n",
    "                                      min_samples_leaf=15, min_samples_split=50,\n",
    "                                      loss='huber', random_state = 5) \n",
    "    \n",
    "    myGBR.fit(X_train,y_train)\n",
    "    pred_train_GBR = myGBR.predict(X_train)\n",
    "\n",
    "    pred_test_GBR = myGBR.predict(X_test)\n",
    "    \n",
    "    # ENet\n",
    "    ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=4.0, l1_ratio=0.005, random_state=3))\n",
    "    ENet.fit(X_train, y_train)\n",
    "    pred_train_ENet = ENet.predict(X_train)\n",
    "    pred_test_ENet = ENet.predict(X_test) \n",
    "    \n",
    "    # LGB\n",
    "    myLGB = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                              learning_rate=0.05, n_estimators=600,\n",
    "                              max_bin = 50, bagging_fraction = 0.6,\n",
    "                              bagging_freq = 5, feature_fraction = 0.25,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf = 6, min_sum_hessian_in_leaf = 11)\n",
    "    myLGB.fit(X_train, y_train)\n",
    "    pred_train_LGB = myLGB.predict(X_train)\n",
    "    pred_test_LGB = myLGB.predict(X_test)      \n",
    "    \n",
    "    # Stacking\n",
    "    stackedset = pd.DataFrame({'A' : []})\n",
    "    stackedset = pd.concat([stackedset,pd.DataFrame(pred_test_l2)],axis=1)\n",
    "    stackedset = pd.concat([stackedset,pd.DataFrame(pred_test_l1)],axis=1)\n",
    "    stackedset = pd.concat([stackedset,pd.DataFrame(pred_test_GBR)],axis=1)\n",
    "    stackedset = pd.concat([stackedset,pd.DataFrame(pred_test_ENet)],axis=1)\n",
    "    stackedset = pd.concat([stackedset,pd.DataFrame(pred_test_LGB)],axis=1)\n",
    "    #prod = (pred_test_l2*pred_test_l1*pred_test_GBR*pred_test_ENet*pred_test_LGB) ** (1.0/5.0)\n",
    "    #stackedset = pd.concat([stackedset,pd.DataFrame(prod)],axis=1)\n",
    "    Xstack = np.array(stackedset)\n",
    "    Xstack = np.delete(Xstack, 0, axis=1)\n",
    "    l1_staked = Lasso(alpha = 0.0001,fit_intercept = True)\n",
    "    l1_staked.fit(Xstack, y_test)\n",
    "    pred_test_stack = l1_staked.predict(Xstack)\n",
    "    models.append([l2Regr,l1Regr,myGBR,ENet,myLGB,l1_staked])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_score = np.array(df_score)\n",
    "X_score =np.delete(X_score,0,1)\n",
    "M=X_score.shape[0]\n",
    "scores_fin = 1+np.zeros(M)\n",
    "for m in models:\n",
    "    ger=m[0]\n",
    "    las=m[1]\n",
    "    gbr=m[2]\n",
    "    Enet=m[3]\n",
    "    lgb=m[4]\n",
    "    las2=m[5]\n",
    "    ger_predict=ger.predict(X_score)\n",
    "    las_predict=las.predict(X_score)\n",
    "    gbr_predict=gbr.predict(X_score)\n",
    "    Enet_predict=Enet.predict(X_score)\n",
    "    lgb_predict=lgb.predict(X_score)\n",
    "    X_stack=pd.DataFrame({\"A\":[]})\n",
    "    X_stack=pd.concat([X_stack,pd.DataFrame(ger_predict),pd.DataFrame(las_predict),pd.DataFrame(gbr_predict),pd.DataFrame(Enet_predict),pd.DataFrame(lgb_predict)],axis=1)\n",
    "    X_stack=np.array(X_stack)\n",
    "    X_stack=np.delete(X_stack,0,1)\n",
    "    scores_fin=scores_fin*(las2.predict(X_stack))\n",
    "scores_fin = scores_fin ** (1/nF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
