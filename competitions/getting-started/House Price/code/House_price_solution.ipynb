{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参考地址\n",
    "[房价预测 (House Prices)](https://github.com/apachecn/kaggle/tree/dev/competitions/getting-started/house-price)  \n",
    "该参考程序有很多BUG，自己修改了一下，才能用，并且该程序只考虑了部分数值型数据，没考虑类别型数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 导入依赖包\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "\n",
    "#机器学习\n",
    "from sklearn.base import BaseEstimator,RegressorMixin,TransformerMixin,clone\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import Lasso,ElasticNet\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "#忽略一些警告\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "#可视化\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1、数据总览"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#查看各列信息，主要看是否有缺失值\n",
    "print(\"训练数据\")\n",
    "train.info()\n",
    "#测试集数据查看\n",
    "print(\"*\"*40)\n",
    "print(\"测试数据\")\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2、数据分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#数值型数据分析\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 相关性协方差表,corr()函数,返回结果接近0说明无相关性,大于0说明是正相关,小于0是负相关.\n",
    "train_corr = train.drop('Id',axis=1).corr()\n",
    "train_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#画热力相关图\n",
    "a = plt.subplots(figsize=(20,12)) #调整画布大小\n",
    "a = sns.heatmap(train_corr,vmax=.8,square=True) #画热力图 annot=True 显示系数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 寻找K个最相关的特征信息\n",
    "k = 10 # number of variables for heatmap\n",
    "#print(train_corr.nlargest(k, 'SalePrice')['SalePrice'])\n",
    "cols = train_corr.nlargest(k, 'SalePrice')['SalePrice'].index #nlargest查看最大的元素\n",
    "#print(cols.values)\n",
    "cm = np.corrcoef(train[cols].values.T)\n",
    "sns.set(font_scale=1.5)\n",
    "hm = plt.subplots(figsize=(20, 12))#调整画布大小\n",
    "hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对上图进行分析\n",
    "GarageCars 和 GarageAre 相关性很高、就像双胞胎一样，所以我们只需要其中的一个变量，例如：GarageCars。<br>\n",
    "TotalBsmtSF  和 1stFloor 与上述情况相同，我们选择 TotalBsmtS<br>\n",
    "GarageAre 和 TotRmsAbvGrd 与上述情况相同，我们选择 GarageAre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set()\n",
    "cols = ['SalePrice', 'OverallQual', 'GrLivArea','GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\n",
    "sns.pairplot(train[cols], size = 2.5)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train[['SalePrice', 'OverallQual', 'GrLivArea','GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "3.特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#将训练集和测试集合并在一起进行分析\n",
    "test['SalePrice'] = None\n",
    "train_test = pd.concat((train, test)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#缺失值\n",
    "total= train_test.isnull().sum().sort_values(ascending=False)\n",
    "percent = total/len(train_test)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total','Lost Percent'])\n",
    "\n",
    "print(missing_data)\n",
    "\n",
    "\n",
    "'''\n",
    "1. 对于缺失率过高的特征，例如 超过15% 我们应该删掉相关变量且假设该变量并不存在\n",
    "2. GarageX 变量群的缺失数据量和概率都相同，可以选择一个就行，例如：GarageCars\n",
    "3. 对于缺失数据在5%左右（缺失率低），可以直接删除/回归预测\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_test = train_test.drop((missing_data[missing_data['Total'] > 1]).index.drop('SalePrice') , axis=1)\n",
    "# train_test = train_test.drop(train.loc[train['Electrical'].isnull()].index)\n",
    "\n",
    "tmp = train_test[train_test['SalePrice'].isnull().values==False]\n",
    "print(tmp.isnull().sum().max()) # justchecking that there's no missing data missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#异常值处理\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "ax1.hist(train.SalePrice)\n",
    "ax2.hist(np.log1p(train.SalePrice))\n",
    "\n",
    "'''\n",
    "从直方图中可以看出：\n",
    "\n",
    "* 偏离正态分布\n",
    "* 数据正偏\n",
    "* 有峰值\n",
    "'''\n",
    "# 数据偏度和峰度度量：\n",
    "\n",
    "print(\"Skewness: %f\" % train['SalePrice'].skew())\n",
    "print(\"Kurtosis: %f\" % train['SalePrice'].kurt())\n",
    "\n",
    "'''\n",
    "低范围的值都比较相似并且在 0 附近分布。\n",
    "高范围的值离 0 很远，并且七点几的值远在正常范围之外。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "var = 'GrLivArea'\n",
    "data = pd.concat([train['SalePrice'], train[var]], axis=1)\n",
    "data.plot.scatter(x=var, y='SalePrice', ylim=(0,800000))\n",
    "\n",
    "'''\n",
    "从图中可以看出：\n",
    "\n",
    "1. 有两个离群的 GrLivArea 值很高的数据，我们可以推测出现这种情况的原因。\n",
    "    或许他们代表了农业地区，也就解释了低价。 这两个点很明显不能代表典型样例，所以我们将它们定义为异常值并删除。\n",
    "2. 图中顶部的两个点是七点几的观测值，他们虽然看起来像特殊情况，但是他们依然符合整体趋势，所以我们将其保留下来。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 删除点\n",
    "print(train.sort_values(by='GrLivArea', ascending = False)[:2])\n",
    "tmp = train_test[train_test['SalePrice'].isnull().values==False]\n",
    "\n",
    "train_test = train_test.drop(tmp[tmp['Id'] == 1299].index)\n",
    "train_test = train_test.drop(tmp[tmp['Id'] == 524].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "var = 'TotalBsmtSF'\n",
    "data = pd.concat([train['SalePrice'],train[var]], axis=1)\n",
    "data.plot.scatter(x=var, y='SalePrice',ylim=(0,800000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(train['SalePrice'], fit=norm)\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(train['SalePrice'], plot=plt)\n",
    "\n",
    "'''\n",
    "可以看出，房价分布不是正态的，显示了峰值，正偏度，但是并不跟随对角线。\n",
    "可以用对数变换来解决这个问题\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 进行对数变换：\n",
    "# 进行对数变换：\n",
    "train_test['SalePrice'] = [i if i is None else np.log1p(i) for i in train_test['SalePrice']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 绘制变换后的直方图和正态概率图：\n",
    "tmp = train_test[train_test['SalePrice'].isnull().values==False]\n",
    "\n",
    "sns.distplot(tmp[tmp['SalePrice'] !=0]['SalePrice'], fit=norm)\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(tmp['SalePrice'], plot=plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(train['GrLivArea'], fit=norm);\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(train['GrLivArea'], plot=plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 进行对数变换：\n",
    "train_test['GrLivArea'] = [i if i is None else np.log1p(i) for i in train_test['GrLivArea']]\n",
    "\n",
    "# 绘制变换后的直方图和正态概率图：\n",
    "tmp = train_test[train_test['SalePrice'].isnull().values==False]\n",
    "sns.distplot(tmp['GrLivArea'], fit=norm)\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(tmp['GrLivArea'], plot=plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(train['TotalBsmtSF'],fit=norm);\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(train['TotalBsmtSF'],plot=plt)\n",
    "\n",
    "'''\n",
    "从图中可以看出：\n",
    "* 显示出了偏度\n",
    "* 大量为 0(Y值) 的观察值（没有地下室的房屋）\n",
    "* 含 0(Y值) 的数据无法进行对数变换\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 去掉为0的分布情况\n",
    "tmp = train_test[train_test['SalePrice'].isnull().values==False]\n",
    "\n",
    "tmp = np.array(tmp.loc[tmp['TotalBsmtSF']>0, ['TotalBsmtSF']])[:, 0]\n",
    "sns.distplot(tmp, fit=norm)\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(tmp, plot=plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 我们建立了一个变量，可以得到有没有地下室的影响值（二值变量），我们选择忽略零值，只对非零值进行对数变换。\n",
    "# 这样我们既可以变换数据，也不会损失有没有地下室的影响。\n",
    "\n",
    "print(train.loc[train['TotalBsmtSF']==0, ['TotalBsmtSF']].count())\n",
    "train.loc[train['TotalBsmtSF']==0,'TotalBsmtSF'] = 1\n",
    "print(train.loc[train['TotalBsmtSF']==1, ['TotalBsmtSF']].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 进行对数变换：\n",
    "tmp = train_test[train_test['SalePrice'].isnull().values==False]\n",
    "\n",
    "print(tmp['TotalBsmtSF'].head(10))\n",
    "train_test['TotalBsmtSF']= np.log1p(train_test['TotalBsmtSF'])\n",
    "\n",
    "tmp = train_test[train_test['SalePrice'].isnull().values==False]\n",
    "print(tmp['TotalBsmtSF'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 绘制变换后的直方图和正态概率图：\n",
    "tmp = train_test[train_test['SalePrice'].isnull().values==False]\n",
    "\n",
    "tmp = np.array(tmp.loc[tmp['TotalBsmtSF']>0, ['TotalBsmtSF']])[:, 0]\n",
    "sns.distplot(tmp, fit=norm)\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(tmp, plot=plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp = train_test[train_test['SalePrice'].isnull().values==False]\n",
    "plt.scatter(tmp['GrLivArea'], tmp['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp = train_test[train_test['SalePrice'].isnull().values==False]\n",
    "plt.scatter(tmp[tmp['TotalBsmtSF']>0]['TotalBsmtSF'], tmp[tmp['TotalBsmtSF']>0]['SalePrice'])\n",
    "\n",
    "# 可以看出 SalePrice 在整个 TotalBsmtSF 变量范围内显示出了同等级别的变化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#将数据集重新拆分成训练集和测试集\n",
    "\n",
    "tmp = train_test[train_test['SalePrice'].isnull().values==False]\n",
    "tmp_1 = train_test[train_test['SalePrice'].isnull().values==True]\n",
    "\n",
    "x_train = tmp[['OverallQual', 'GrLivArea','GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']]\n",
    "y_train = tmp[[\"SalePrice\"]].values.ravel()\n",
    "\n",
    "x_test = tmp_1[['OverallQual', 'GrLivArea','GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']]\n",
    "\n",
    "# 简单测试，用中位数来替代\n",
    "# print(x_test.GarageCars.mean(), x_test.GarageCars.median(), x_test.TotalBsmtSF.mean(), x_test.TotalBsmtSF.median())\n",
    "\n",
    "x_test[\"GarageCars\"].fillna(x_test.GarageCars.median(), inplace=True)\n",
    "x_test[\"TotalBsmtSF\"].fillna(x_test.TotalBsmtSF.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Bag回归\n",
    "ridge = Ridge(alpha=0.1)\n",
    "\n",
    "# bagging 把很多小的分类器放在一起，每个train随机的一部分数据，然后把它们的最终结果综合起来（多数投票）\n",
    "# bagging 算是一种算法框架\n",
    "params = [1, 10, 20, 40, 60]\n",
    "test_scores = []\n",
    "for param in params:\n",
    "    clf = BaggingRegressor(base_estimator=ridge, n_estimators=param)\n",
    "    # cv=5表示cross_val_score采用的是k-fold cross validation的方法，重复5次交叉验证\n",
    "    # scoring='precision'、scoring='recall'、scoring='f1', scoring='neg_mean_squared_error' 方差值\n",
    "    test_score = np.sqrt(-cross_val_score(clf, x_train, y_train, cv=10, scoring='neg_mean_squared_error'))\n",
    "    test_scores.append(np.mean(test_score))\n",
    "\n",
    "print(test_score.mean())\n",
    "plt.plot(params, test_scores)\n",
    "plt.title('n_estimators vs CV Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Validation function\n",
    "from sklearn.model_selection import KFold\n",
    "n_folds = 5\n",
    "\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train.values)\n",
    "    rmse= np.sqrt(-cross_val_score(model,  x_train.values, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 模型选择\n",
    "\n",
    "## LASSO Regression :\n",
    "lasso = make_pipeline(RobustScaler(), Lasso(alpha=0.0005, random_state=1))\n",
    "#Elastic Net Regression\n",
    "ENet = make_pipeline(\n",
    "    RobustScaler(), ElasticNet(\n",
    "        alpha=0.0005, l1_ratio=.9, random_state=3))\n",
    "#Kernel Ridge Regression\n",
    "KRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\n",
    "## Gradient Boosting Regression\n",
    "GBoost = GradientBoostingRegressor(\n",
    "    n_estimators=3000,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=4,\n",
    "    max_features='sqrt',\n",
    "    min_samples_leaf=15,\n",
    "    min_samples_split=10,\n",
    "    loss='huber',\n",
    "    random_state=5)\n",
    "## XGboost\n",
    "model_xgb = xgb.XGBRegressor(\n",
    "    colsample_bytree=0.4603,\n",
    "    gamma=0.0468,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=3,\n",
    "    min_child_weight=1.7817,\n",
    "    n_estimators=2200,\n",
    "    reg_alpha=0.4640,\n",
    "    reg_lambda=0.8571,\n",
    "    subsample=0.5213,\n",
    "    silent=1,\n",
    "    random_state=7,\n",
    "    nthread=-1)\n",
    "## lightGBM\n",
    "model_lgb = lgb.LGBMRegressor(\n",
    "    objective='regression',\n",
    "    num_leaves=5,\n",
    "    learning_rate=0.05,\n",
    "    n_estimators=720,\n",
    "    max_bin=55,\n",
    "    bagging_fraction=0.8,\n",
    "    bagging_freq=5,\n",
    "    feature_fraction=0.2319,\n",
    "    feature_fraction_seed=9,\n",
    "    bagging_seed=9,\n",
    "    min_data_in_leaf=6,\n",
    "    min_sum_hessian_in_leaf=11)\n",
    "## 对这些基本模型进行打分\n",
    "score = rmsle_cv(lasso)\n",
    "print(\"\\nLasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "score = rmsle_cv(ENet)\n",
    "print(\"ElasticNet score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "score = rmsle_cv(KRR)\n",
    "print(\n",
    "    \"Kernel Ridge score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "score = rmsle_cv(GBoost)\n",
    "print(\"Gradient Boosting score: {:.4f} ({:.4f})\\n\".format(score.mean(),\n",
    "                                                          score.std()))\n",
    "score = rmsle_cv(model_xgb)\n",
    "print(\"Xgboost score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "score = rmsle_cv(model_lgb)\n",
    "print(\"LGBM score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "ridge = Ridge(alpha=0.1)\n",
    "\n",
    "train_sizes, train_loss, test_loss = learning_curve(ridge, x_train, y_train, cv=10, \n",
    "                                                    scoring='neg_mean_squared_error',\n",
    "                                                    train_sizes = [0.1, 0.3, 0.5, 0.7, 0.9 , 0.95, 1])\n",
    "\n",
    "# 训练误差均值\n",
    "train_loss_mean = -np.mean(train_loss, axis = 1)\n",
    "# 测试误差均值\n",
    "test_loss_mean = -np.mean(test_loss, axis = 1)\n",
    "\n",
    "# 绘制误差曲线\n",
    "plt.plot(train_sizes/len(x_train), train_loss_mean, 'o-', color = 'r', label = 'Training')\n",
    "plt.plot(train_sizes/len(x_train), test_loss_mean, 'o-', color = 'g', label = 'Cross-Validation')\n",
    "\n",
    "plt.xlabel('Training data size')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc = 'best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mode_br = BaggingRegressor(base_estimator=ridge, n_estimators=10)\n",
    "mode_br.fit(x_train, y_train)\n",
    "y_test = np.expm1(mode_br.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "# 模型融合\n",
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "\n",
    "    # we define clones of the original models to fit the data in\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "\n",
    "        # Train cloned base models\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    # Now we do the predictions for cloned models and average them\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack(\n",
    "            [model.predict(X) for model in self.models_])\n",
    "        return np.mean(predictions, axis=1)\n",
    "\n",
    "\n",
    "# 评价这四个模型的好坏\n",
    "averaged_models = AveragingModels(models=(ENet, GBoost, KRR, lasso))\n",
    "score = rmsle_cv(averaged_models)\n",
    "print(\" Averaged base models score: {:.4f} ({:.4f})\\n\".format(score.mean(),\n",
    "                                                              score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stack模型融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    # We again fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        \n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "                \n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stacked_averaged_models = StackingAveragedModels(base_models = (ENet, GBoost, KRR),\n",
    "                                                 meta_model = lasso)\n",
    "\n",
    "score = rmsle_cv(stacked_averaged_models)\n",
    "print(\"Stacking Averaged models score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rmsle(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stacked_averaged_models.fit(x_train.values, y_train)\n",
    "stacked_train_pred = stacked_averaged_models.predict(x_train.values)\n",
    "stacked_pred = np.expm1(stacked_averaged_models.predict(x_test.values))\n",
    "print(rmsle(y_train, stacked_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_xgb.fit(x_train, y_train)\n",
    "xgb_train_pred = model_xgb.predict(x_train)\n",
    "xgb_pred = np.expm1(model_xgb.predict(x_test))\n",
    "print(rmsle(y_train, xgb_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_lgb.fit(x_train, y_train)\n",
    "lgb_train_pred = model_lgb.predict(x_train)\n",
    "lgb_pred = np.expm1(model_lgb.predict(x_test.values))\n",
    "print(rmsle(y_train, lgb_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''RMSE on the entire Train data when averaging'''\n",
    "\n",
    "print('RMSLE score on train data:')\n",
    "print(rmsle(y_train,stacked_train_pred*0.70 +\n",
    "               xgb_train_pred*0.15 + lgb_train_pred*0.15 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensemble = stacked_pred*0.70 + xgb_pred*0.15 + lgb_pred*0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['Id'] = test.Id\n",
    "sub['SalePrice'] = ensemble\n",
    "sub.to_csv('../out/submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
