{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 数据分析\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 机器学习\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.model_selection import StratifiedKFold,GridSearchCV,train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "\n",
    "#用于模型保存\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "#可视化\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1、数据总览"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/train.csv')\n",
    "test_df = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#查看各列信息，主要看是否有缺失值\n",
    "print(\"训练数据\")\n",
    "train_df.info()\n",
    "#测试集数据查看\n",
    "print(\"测试数据\")\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2、数据分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#数值型数据分析\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df['Survived'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 相关性协方差表,corr()函数,返回结果接近0说明无相关性,大于0说明是正相关,小于0是负相关.\n",
    "train_corr = train_df.drop('PassengerId',axis=1).corr()\n",
    "train_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#画热力相关图\n",
    "a = plt.subplots(figsize=(15,9))\n",
    "a = sns.heatmap(train_corr,vmin=-1,vmax=1,annot=True,square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#分析乘客等级和生存下来的关系\n",
    "train_df.groupby(['Pclass'])['Pclass','Survived'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#分析乘客等级和生存下来的关系\n",
    "train_df[['Pclass','Survived']].groupby(['Pclass']).mean().plot.bar(color=['r','g','b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#单独分析性别与生存下来的关系\n",
    "train_df.groupby(['Sex'])['Sex','Survived'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#单独分析性别与生存下来的关系\n",
    "train_df[['Sex','Survived']].groupby(['Sex']).mean().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#性别和船舱等级与生存的关系\n",
    "train_df[['Sex','Pclass','Survived']].groupby(['Pclass','Sex']).mean().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#性别和船舱等级与生存的关系\n",
    "train_df.groupby(['Sex','Pclass','Survived'])['Survived'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#分析兄弟配偶数量和生存下来的关系\n",
    "train_df.groupby(['SibSp'])[['SibSp','Survived']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#分析兄弟配偶数量和生存下来的关系\n",
    "train_df[['SibSp','Survived']].groupby(['SibSp']).mean().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#分析父母子女数量和生存下来的关系\n",
    "train_df.groupby('Parch')[['Parch','Survived']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#分析父母子女数量和生存下来的关系\n",
    "train_df[['Parch','Survived']].groupby(['Parch']).mean().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#分析年龄和生存下来的关系，年龄有缺失值\n",
    "g = sns.FacetGrid(train_df,col='Survived',size=5)\n",
    "g.map(plt.hist,'Age',bins=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df.groupby(['Age'])['Survived'].mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#登陆港口和生存的关系\n",
    "sns.countplot('Embarked',hue='Survived',data=train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3、特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#先将数据集合并,一起做特征工程(注意,标准化的时候需要分开处理)\n",
    "#先将test补齐,然后通过pd.apped()合并\n",
    "test_df['Survived'] = 0\n",
    "train_test = train_df.append(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_test.shape\n",
    "train_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#利用get_dummies函数进行Pclass独热处理\n",
    "train_test = pd.get_dummies(train_test,columns=['Pclass'])\n",
    "train_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#对sex分裂处理\n",
    "train_test = pd.get_dummies(train_test,columns=[\"Sex\"])\n",
    "train_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#对兄弟姐妹以及父母子女进行处理\n",
    "train_test['SibSp_Parch'] = train_test['SibSp']+train_test['Parch']\n",
    "train_test = pd.get_dummies(train_test,columns=['SibSp','Parch','SibSp_Parch'])\n",
    "train_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_test.info()\n",
    "#对Embarked进行处理\n",
    "train_test = pd.get_dummies(train_test,columns=[\"Embarked\"])\n",
    "train_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#对Name进行处理\n",
    "train_test['Name1']=train_test['Name'].str.extract('.+,(.+)',expand=False).str.extract('^(.+?)\\.',expand=False).str.strip()\n",
    "#train_test['Name1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#将姓名分类处理()\n",
    "train_test['Name1'].replace(['Capt', 'Col', 'Major', 'Dr', 'Rev'], 'Officer' , inplace = True)\n",
    "train_test['Name1'].replace(['Jonkheer', 'Don', 'Sir', 'the Countess', 'Dona', 'Lady'], 'Royalty' , inplace = True)\n",
    "train_test['Name1'].replace(['Mme', 'Ms', 'Mrs'], 'Mrs')\n",
    "train_test['Name1'].replace(['Mlle', 'Miss'], 'Miss')\n",
    "train_test['Name1'].replace(['Mr'], 'Mr' , inplace = True)\n",
    "train_test['Name1'].replace(['Master'], 'Master' , inplace = True)\n",
    "#train_test['Name1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_test=pd.get_dummies(train_test,columns=[\"Name1\"])\n",
    "#train_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#从姓名中提取出姓\n",
    "train_test['Name2'] = train_test['Name'].apply(lambda x: x.split('.')[1])\n",
    "\n",
    "# #计算数量,然后合并数据集\n",
    "Name2_sum = train_test['Name2'].value_counts().reset_index()\n",
    "Name2_sum.columns=['Name2','Name2_sum']\n",
    "train_test = pd.merge(train_test,Name2_sum,how='left',on='Name2')\n",
    "\n",
    "#由于出现一次时该特征时无效特征,用one来代替出现一次的姓\n",
    "train_test.loc[train_test['Name2_sum'] == 1 , 'Name2_new'] = 'one'\n",
    "train_test.loc[train_test['Name2_sum'] > 1 , 'Name2_new'] = train_test['Name2']\n",
    "del train_test['Name2']\n",
    "\n",
    "# #分列处理\n",
    "train_test = pd.get_dummies(train_test,columns=['Name2_new'])\n",
    "#删掉姓名这个特征\n",
    "del train_test['Name']\n",
    "\n",
    "#train_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#处理Fare变量\n",
    "train_test.loc[train_test[\"Fare\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#处理Fare变量，由于变量和Pclass以及Embarked有关\n",
    "train_df.groupby(by=[\"Pclass\",\"Embarked\"]).Fare.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#用pclass=3和Embarked=S的平均数14.644083来替换\n",
    "train_test['Fare'].fillna(14.644083,inplace=True)\n",
    "train_test.loc(train_test['Fare'].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#将Ticket提取字符列\n",
    "#str.isnumeric()  如果S中只有数字字符，则返回True，否则返回False\n",
    "train_test['Ticket']\n",
    "train_test['Ticket_Letter'] = train_test['Ticket'].str.split().str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_test['Ticket_Letter'] = train_test['Ticket_Letter'].apply(lambda x:np.nan if x.isnumeric() else x)\n",
    "train_test.drop('Ticket',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#分列,此时nan值可以不做处理\n",
    "train_test = pd.get_dummies(train_test,columns=['Ticket_Letter'],drop_first=True)\n",
    "#train_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Age\n",
    "train_test.loc[train_test['Age'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"这是模型就好后回来增加的新特征\n",
    "考虑年龄缺失值可能影响死亡情况,数据表明,年龄缺失的死亡率为0.19.\"\"\"\n",
    "train_test.loc[train_test[\"Age\"].isnull()]['Survived'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#利用年龄是否缺失来构造新特征\n",
    "train_test.loc[train_test[\"Age\"].isnull(),\"age_nan\"]=1\n",
    "train_test.loc[train_test[\"Age\"].notnull(),\"age_nan\"]=0\n",
    "train_test=pd.get_dummies(train_test,columns=[\"age_nan\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#创建没有[\"Age\"，\"Survived\"]的数据集\n",
    "missing_age = train_test.drop(['Survived','Cabin'],axis=1)\n",
    "#将Age完整的项作为训练集、将Age缺失的项作为测试集。\n",
    "missing_age_train = missing_age[missing_age['Age'].notnull()]\n",
    "missing_age_test = missing_age[missing_age['Age'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#构建训练集合预测集的X和Y值\n",
    "missing_age_X_train = missing_age_train.drop(['Age'], axis=1)\n",
    "missing_age_Y_train = missing_age_train['Age']\n",
    "missing_age_X_test = missing_age_test.drop(['Age'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 先将数据标准化\n",
    "ss = StandardScaler()\n",
    "#用测试集训练并标准化\n",
    "ss.fit(missing_age_X_train)\n",
    "missing_age_X_train = ss.transform(missing_age_X_train)\n",
    "missing_age_X_test = ss.transform(missing_age_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#使用贝叶斯预测年龄\n",
    "lin = BayesianRidge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lin.fit(missing_age_X_train,missing_age_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#利用loc将预测值填入数据集\n",
    "train_test.loc[(train_test['Age'].isnull()), 'Age'] = lin.predict(missing_age_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#将年龄划分是个阶段10以下,10-18,18-30,30-50,50以上\n",
    "train_test['Age'] = pd.cut(train_test['Age'], bins=[0,10,18,30,50,100],labels=[1,2,3,4,5])\n",
    "\n",
    "train_test = pd.get_dummies(train_test,columns=['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cabin项缺失太多，只能将有无Cain首字母进行分类,缺失值为一类,作为特征值进行建模\n",
    "train_test['Cabin_nan'] = train_test['Cabin'].apply(lambda x:str(x)[0] if pd.notnull(x) else x)\n",
    "train_test = pd.get_dummies(train_test,columns=['Cabin_nan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " #cabin项缺失太多，只能将有无Cain首字母进行分类,\n",
    "train_test.loc[train_test[\"Cabin\"].isnull() ,\"Cabin_nan\"] = 1\n",
    "train_test.loc[train_test[\"Cabin\"].notnull() ,\"Cabin_nan\"] = 0\n",
    "train_test = pd.get_dummies(train_test,columns=['Cabin_nan'])\n",
    "train_test.drop('Cabin',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#特征工程完毕，划分数据集\n",
    "train_data = train_test[:891]\n",
    "test_data = train_test[891:]\n",
    "train_data_X = train_data.drop(['Survived'],axis=1)\n",
    "train_data_Y = train_data['Survived']\n",
    "test_data_X = test_data.drop(['Survived'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(train_data_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 标准化\n",
    "ss2 = StandardScaler()\n",
    "ss2.fit(train_data_X)\n",
    "train_data_X_sd = ss2.transform(train_data_X)\n",
    "test_data_X_sd = ss2.transform(test_data_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4、建立基模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Logistic\n",
    "\n",
    "#划分训练集和测试集\n",
    "train_data,dev_data,train_label,dev_label = train_test_split(train_data_X_sd,train_data_Y,test_size=0.1,random_state=34)\n",
    "\n",
    "lr1=LogisticRegression()\n",
    "param={'C':[0.001,0.01,0.1,1,10],\"max_iter\":[100,250]}\n",
    "clf = GridSearchCV(lr1,param,cv=5)\n",
    "clf.fit(train_data,train_label)\n",
    "\n",
    "#打印结果\n",
    "print(clf.grid_scores_)\n",
    "print(clf.best_params_)\n",
    "\n",
    "#将最佳参数输入模型\n",
    "lr = LogisticRegression(C=0.01,max_iter=100)\n",
    "lr.fit(train_data, train_label)\n",
    "\n",
    "print(lr.score(dev_data,dev_label))\n",
    "# 输出结果\n",
    "test_df[\"Survived\"] = lr.predict(test_data_X_sd)\n",
    "test_df[[\"PassengerId\",\"Survived\"]].set_index(\"PassengerId\").to_csv('../out/LR.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 随机森林\n",
    "rf = RandomForestClassifier(n_estimators=150,min_samples_leaf=3,max_depth=6,oob_score=True)\n",
    "rf.fit(train_data_X,train_data_Y)\n",
    "print(rf.oob_score_)\n",
    "test_df[\"Survived\"] = rf.predict(test_data_X)\n",
    "RF = test_df[['PassengerId','Survived']].set_index('PassengerId').to_csv('../out/RF.csv')\n",
    "\n",
    "# # 保存模型\n",
    "# from sklearn.externals import joblib\n",
    "# joblib.dump(rf, '../model/rf10.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#svm算法\n",
    "svc = SVC()\n",
    "svc.fit(train_data,train_label)\n",
    "print(svc.score(dev_data,dev_label))\n",
    "#预测保存数据\n",
    "test_df[\"Survived\"]=svc.predict(test_data_X_sd)\n",
    "test_df[[\"PassengerId\",\"Survived\"]].set_index(\"PassengerId\").to_csv('../out/SVM.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#GBDT\n",
    "\n",
    "gbdt = GradientBoostingClassifier(learning_rate=0.7,max_depth=6,n_estimators=100,min_samples_leaf=2)\n",
    "gbdt.fit(train_data_X,train_data_Y)\n",
    "\n",
    "test_df[\"Survived\"] = gbdt.predict(test_data_X)\n",
    "test_df[['PassengerId','Survived']].set_index('PassengerId').to_csv('../out/GBDT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#XGBoost\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(n_estimators=150,min_samples_leaf=3,max_depth=6)\n",
    "xgb_model.fit(train_data_X,train_data_Y)\n",
    "\n",
    "test_df[\"Survived\"] = xgb_model.predict(test_data_X)\n",
    "test_df[['PassengerId','Survived']].set_index('PassengerId').to_csv('../out/XGB.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5、模型融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#模型Voting\n",
    "\n",
    "lr = LogisticRegression(C=0.1,max_iter=100)\n",
    "xgb_model = xgb.XGBClassifier(max_depth=6,min_samples_leaf=2,n_estimators=100,num_round = 5)\n",
    "rf = RandomForestClassifier(n_estimators=200,min_samples_leaf=2,max_depth=6,oob_score=True)\n",
    "gbdt = GradientBoostingClassifier(learning_rate=0.1,min_samples_leaf=2,max_depth=6,n_estimators=100)\n",
    "\n",
    "vot = VotingClassifier(estimators=[('lr', lr), ('rf', rf),('gbdt',gbdt),('xgb',xgb_model)], voting='hard')\n",
    "vot.fit(train_data_X_sd,train_data_Y)\n",
    "\n",
    "test_df[\"Survived\"] = vot.predict(test_data_X_sd)\n",
    "test_df[['PassengerId','Survived']].set_index('PassengerId').to_csv('../out/VOT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#模型stacking\n",
    "# 划分train数据集,调用代码,把数据集名字转成和代码一样\n",
    "X = train_data_X_sd\n",
    "X_predict = test_data_X_sd\n",
    "y = train_data_Y\n",
    "\n",
    "'''模型融合中使用到的各个单模型'''\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clfs = [LogisticRegression(C=0.1,max_iter=100),\n",
    "        xgb.XGBClassifier(max_depth=6,n_estimators=100,num_round = 5),\n",
    "        RandomForestClassifier(n_estimators=100,max_depth=6,oob_score=True),\n",
    "        GradientBoostingClassifier(learning_rate=0.3,max_depth=6,n_estimators=100)]\n",
    "\n",
    "# 创建n_folds\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "n_folds = 5\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "skf.get_n_splits(X,y)\n",
    "# 创建零矩阵\n",
    "dataset_blend_train = np.zeros((X.shape[0], len(clfs)))\n",
    "dataset_blend_test = np.zeros((X_predict.shape[0], len(clfs)))\n",
    "\n",
    "# 建立模型\n",
    "for j, clf in enumerate(clfs):\n",
    "    '''依次训练各个单模型'''\n",
    "    # print(j, clf)\n",
    "    dataset_blend_test_j = np.zeros((X_predict.shape[0], skf.get_n_splits(X,y)))\n",
    "    i=0;\n",
    "    for train_index, test_index in skf.split(X,y):\n",
    "        '''使用第i个部分作为预测，剩余的部分来训练模型，获得其预测的输出作为第i部分的新特征。'''\n",
    "        X_train, y_train, X_test, y_test = X[train_index], y[train_index], X[test_index], y[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_submission = clf.predict_proba(X_test)[:, 1]\n",
    "        dataset_blend_train[test_index, j] = y_submission\n",
    "        dataset_blend_test_j[:, i] = clf.predict_proba(X_predict)[:, 1]\n",
    "        i+=1\n",
    "    '''对于测试集，直接用这k个模型的预测值均值作为新的特征。'''\n",
    "    dataset_blend_test[:, j] = dataset_blend_test_j.mean(1)\n",
    "\n",
    "# 用建立第二层模型\n",
    "clf2 = LogisticRegression(C=0.1,max_iter=100)\n",
    "clf2.fit(dataset_blend_train, y)\n",
    "# y_submission = clf2.predict_proba(dataset_blend_test)[:, 1]\n",
    "\n",
    "\n",
    "test_df[\"Survived\"] = clf2.predict(dataset_blend_test)\n",
    "test_df[['PassengerId','Survived']].set_index('PassengerId').to_csv('../out/Stack.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
